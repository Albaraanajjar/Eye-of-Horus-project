# -*- coding: utf-8 -*-
"""training_AI_Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eIVqWEWtsAGWTrY_yvhWKqYrDFPb_LVD
"""

import numpy as np 
import pandas as pd 
import zipfile
import matplotlib.pyplot as plt
import tensorflow as tf
import os
import shutil

from tensorflow import keras
from keras import layers
from keras.models import Sequential

from tensorflow.keras.optimizers import RMSprop
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.applications import VGG16
from tensorflow.keras.callbacks import EarlyStopping

!python --version

tf.__version__

keras.__version__

import glob
import zipfile
##put path of file that have compressed satallite data
for file_zip in glob.glob('/content/drive/MyDrive/amazon_project/satellite data/*.zip'):
    with zipfile.ZipFile(file_zip, 'r') as zip_ref:
        zip_ref.extractall()

import glob
import zipfile
#put path of file that have compressed drone data
for file_zip in glob.glob('/content/drive/MyDrive/amazon_project/drone/*.zip'):
    with zipfile.ZipFile(file_zip, 'r') as zip_ref:
        zip_ref.extractall()

path_train='/content/training' 
train_datagen = ImageDataGenerator(rescale = 1./255, #data augementation to avoid over-fitting
                                   validation_split=0.2,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                  )
training_set = train_datagen.flow_from_directory(path_train,
                                                 target_size = (256,256),
                                                 subset='training',
                                                  color_mode='rgb',
                                                 batch_size = 32,
                                                 class_mode = 'binary')
validation_generator = train_datagen.flow_from_directory(path_train, class_mode='binary', batch_size = 32, target_size=(256,256), subset='validation', shuffle=True, seed=42)

test_datagen=ImageDataGenerator(rescale = 1./255)
test_generator = test_datagen.flow_from_directory(
        '/content/test',
        target_size=(256, 256),
        color_mode='rgb',
        batch_size=1,
        class_mode='binary')

"""
#################################
 Fire Segmentation on Fire Class to extract fire pixels from each frame based on the Ground Truth data (masks)
################################
"""

#########################################################
# import libraries
import os
import random
import numpy as np
from tqdm import tqdm
import tensorflow as tf
import matplotlib.pyplot as plt

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import concatenate
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dropout, Lambda
from tensorflow.keras.layers import Conv2D, Conv2DTranspose

segmentation_new_size = {'width': 512, 'height': 512}
config_segmentation = {"batch_size": 16, 'Save_Model': False, 'Epochs': 30, "TrainingPlot": False,
                       "train_set_ratio": 0.85, "val_set_ratio": 0.15, "num_class": 2, "CHANNELS": 3}

#########################################################
# Global parameters and definition

METRICS = [
    tf.keras.metrics.AUC(name='auc'),
    tf.keras.metrics.Recall(name='recall'),
    tf.keras.metrics.TruePositives(name='tp'),
    tf.keras.metrics.TrueNegatives(name='tn'),
    tf.keras.metrics.FalsePositives(name='fp'),
    tf.keras.metrics.FalseNegatives(name='fn'),
    tf.keras.metrics.Accuracy(name='accuracy'),
    tf.keras.metrics.Precision(name='precision'),
    tf.keras.metrics.MeanIoU(num_classes=2, name='iou'),
    tf.keras.metrics.BinaryAccuracy(name='bin_accuracy'),
]


#########################################################
# Function definition

def segmentation_keras_load():
    """
    This function trains a DNN model for the fire segmentation based on the U-NET Structure.
    
    :return: None, Save the model
    """

    """ Defining general parameters """
    batch_size = config_segmentation.get('batch_size')
    img_size = (segmentation_new_size.get("width"), segmentation_new_size.get("height"))
    img_width = img_size[0]
    img_height = img_size[1]
    epochs = config_segmentation.get('Epochs')
    img_channels = config_segmentation.get('CHANNELS')
    dir_images = "/content/Images"
    dir_masks = "/content/Masks"
    num_classes = config_segmentation.get("num_class")

    """ Start reading data (Frames and masks) and save them in Numpy array for Training, Validation and Test"""
    allfiles_image = sorted(
        [
            os.path.join(dir_images, fname)
            for fname in tqdm(os.listdir(dir_images))
            if fname.endswith(".jpg")
        ]
    )
    allfiles_mask = sorted(
        [
            os.path.join(dir_masks, fname)
            for fname in tqdm(os.listdir(dir_masks))
            if fname.endswith(".png") and not fname.startswith(".")
        ]
    )

    print("Number of samples:", len(allfiles_image))
    for input_path, target_path in tqdm(zip(allfiles_image[:10], allfiles_mask[:10])):
        print(input_path, "|", target_path)
    total_samples = len(allfiles_mask)
    train_ratio = config_segmentation.get("train_set_ratio")
    val_samples = int(total_samples * (1 - train_ratio))
    random.Random(1337).shuffle(allfiles_image)
    random.Random(1337).shuffle(allfiles_mask)
    train_img_paths = allfiles_image[:-val_samples]
    train_mask_paths = allfiles_mask[:-val_samples]
    val_img_paths = allfiles_image[-val_samples:]
    val_mask_paths = allfiles_mask[-val_samples:]

    x_train = np.zeros((len(train_img_paths), img_height, img_width, img_channels), dtype=np.uint8)
    y_train = np.zeros((len(train_mask_paths), img_height, img_width, 1), dtype=np.bool)

    x_val = np.zeros((len(val_img_paths), img_height, img_width, img_channels), dtype=np.uint8)
    y_val = np.zeros((len(val_mask_paths), img_height, img_width, 1), dtype=np.bool)
    print('\nLoading training images: ', len(train_img_paths), 'images ...')
    for n, file_ in tqdm(enumerate(train_img_paths)):
        img = tf.keras.preprocessing.image.load_img(file_, target_size=img_size)
        x_train[n] = img

    print('\nLoading training masks: ', len(train_mask_paths), 'masks ...')
    for n, file_ in tqdm(enumerate(train_mask_paths)):
        img = tf.keras.preprocessing.image.load_img(file_, target_size=img_size, color_mode="grayscale")
        y_train[n] = np.expand_dims(img, axis=2)
        # y_train[n] = y_train[n] // 255

    print('\nLoading test images: ', len(val_img_paths), 'images ...')
    for n, file_ in tqdm(enumerate(val_img_paths)):
        img = tf.keras.preprocessing.image.load_img(file_, target_size=img_size)
        x_val[n] = img

    print('\nLoading test masks: ', len(val_mask_paths), 'masks ...')
    for n, file_ in tqdm(enumerate(val_mask_paths)):
        img = tf.keras.preprocessing.image.load_img(file_, target_size=img_size, color_mode="grayscale")
        y_val[n] = np.expand_dims(img, axis=-1)
        # y_val[n] = y_val[n] // 255

   
    tf.keras.backend.clear_session()

    """ Training the Model ... """
    model = model_unet_kaggle(img_height, img_width, img_channels, num_classes)
    
    model.compile(optimizer="adam", loss="binary_crossentropy", metrics=METRICS)
    checkpoint = tf.keras.callbacks.ModelCheckpoint("FireSegmentation.h5", save_best_only=True)
    early_stopper = tf.keras.callbacks.EarlyStopping(patience=5)

    results = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size,
                        callbacks=[early_stopper, checkpoint])

    """ Prediciting some masks using the model ... """
    model_predict = tf.keras.models.load_model("FireSegmentation_fifth.h5")
    preds_val = model.predict(x_val, verbose=1)
    preds_val_t = (preds_val > 0.5).astype(np.uint8)



def model_unet_kaggle(img_hieght, img_width, img_channel, num_classes):
    """
    This function returns a U-Net Model for this binary fire segmentation images:
    
    :param img_hieght: Image Height
    :param img_width: Image Width
    :param img_channel: Number of channels in each image
    :param num_classes: Number of classes based on the Ground Truth Masks
    :return: A convolutional CNN based on Tensorflow and Keras
    """
    inputs = Input((img_hieght, img_width, img_channel))
    s = Lambda(lambda x: x / 255)(inputs)

    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5)

    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model

model=segmentation_keras_load()
model

import matplotlib.pyplot as plt


def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.show()

transfered_model=keras.models.load_model('/content/drive/MyDrive/amazon_project/models/transfered_model.h5') #load transfered model
transfered_model.trainable=False

new_model=keras.models.clone_model(transfered_model) #cloned the model to preserve weights of original model

new_model.set_weights(transfered_model.get_weights())

for layer in new_model.layers[:-3]: #to btrain only the last few layers
    layer.trainable = False

def piecewise_constant_fn(epoch):
    if epoch < 5:
        return 0.01
    elif epoch < 15:
        return 0.005
    else:
        return 0.001

new_model.compile(loss="binary_crossentropy",
                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),
                     metrics=["accuracy"])

print("weights:", len(layer.weights))
print("trainable_weights:", len(layer.trainable_weights))
print("non_trainable_weights:", len(layer.non_trainable_weights))

lr_scheduler=keras.callbacks.LearningRateScheduler(piecewise_constant_fn) #peice_wise schedualing to avoid overfitting

history=new_model.fit(training_set,epochs=20,validation_data=validation_generator,callbacks=[lr_scheduler])

plot_hist(history)

new_model.evaluate(test_generator)

new_model.save("my_final_model.h5")